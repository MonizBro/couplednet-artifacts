{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f95ea5b-bc47-4fb2-ab93-b8ce37a5ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os, sys, time, gc, random\n",
    "\n",
    "# PyTorch Core Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, AdamW\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "# Additional Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# System Monitoring (GPU/CPU)\n",
    "import psutil\n",
    "from pynvml import *\n",
    "\n",
    "# Initialize NVML for GPU monitoring\n",
    "nvmlInit()\n",
    "gc.collect()  # Explicitly call garbage collection to clean up memory\n",
    "torch.cuda.empty_cache()  # Clear unused memory\n",
    "\n",
    "\"\"\" Reproducibility \"\"\"\n",
    "# Define seed value\n",
    "seed = 42\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(seed)  # Python's random module\n",
    "np.random.seed(seed)  # NumPy random module\n",
    "torch.manual_seed(seed)  # PyTorch CPU random seed\n",
    "# Check if CUDA is available and set the seed for CUDA as well\n",
    "torch.cuda.manual_seed_all(seed) # PyTorch GPU random seed (for all devices, if multi-GPU)\n",
    "\n",
    "# For deterministic behavior with cuDNN (when using GPU)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False  # Disables the cudnn autotuner to ensure reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2faad03-8864-463b-9ba4-c1d839054a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"ViT_L_32\" # Target Model\n",
    "DATASET_NAME = \"CIFAR100\" # Target dataset\n",
    "NUM_CLASSES = 100 # No of classes\n",
    "split_ratio = 0.85 # Split training set into training and validation\n",
    "weights_name = MODEL_NAME + \"_Weights\"\n",
    "ALPHA = 2048 # Couplin Factor\n",
    "\n",
    "# Define the folder to save the Results\n",
    "FOLDER_NAME = f\"{MODEL_NAME}-{DATASET_NAME}\"\n",
    "    \n",
    "# Check if the folder exists, if not create it\n",
    "if not os.path.exists(FOLDER_NAME):\n",
    "    os.makedirs(FOLDER_NAME)\n",
    "\n",
    "# Save the log file in the specified folder\n",
    "log_file_path = os.path.join(FOLDER_NAME, f\"{MODEL_NAME}_{DATASET_NAME}_a{ALPHA}-logfile.txt\")\n",
    "log_file = open(log_file_path, 'w')\n",
    "\n",
    "# Redirect the standard output to the file\n",
    "sys.stdout = log_file\n",
    "\n",
    "# Check the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'{device} is available...')\n",
    "# Get the number of GPUs (if any) available using PyTorch\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of GPUs available: {num_gpus}\")\n",
    "# If GPUs are available, print the name of the first GPU\n",
    "if num_gpus > 0:\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\\n\")  # Print the name of the first GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d1f13c-4f5e-4967-81f8-850f99ebf461",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5256519c-747e-4157-8bc4-29aa2b599bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.85 # Split training set into training and validation\n",
    "batch_size = 256 # Number of samples per batch\n",
    "num_workers = 16  # Number of subprocesses for data loading\n",
    "learning_rate = 2e-5 # Model's weights updatig factor during training\n",
    "num_epochs = 100 # Number of times to iterate over the entire training dataset\n",
    "train_criterion = nn.CrossEntropyLoss(label_smoothing=0.1) # Define the loss function used to train the model\n",
    "val_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Early stopping parameters to prevent overfitting\n",
    "patience = 10 # Stop training if validation loss doesn't improve for \"patience\" epochs\n",
    "best_val_loss = float('inf') # Track the best validation loss encountered during training\n",
    "epochs_without_improvement = 0 # Counter to monitor no improvements in validation loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33d3a46-e513-45ad-a243-492c902cc5c9",
   "metadata": {},
   "source": [
    "# Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d52c2a-4292-46d1-84ee-64445459bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import RandAugment\n",
    "RandAugment()\n",
    "\n",
    "# Data augmentation and normalization\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    RandAugment(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])  # CIFAR-100\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55506d25-9794-4be1-b8ea-e408f654003b",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4cb4af-2771-446c-a0fa-92e3d9c72fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedDataset(Dataset):\n",
    "    def __init__(self, dataset, transform):\n",
    "        # wrap an exisiting dataset and apply a transform to each image\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, index):\n",
    "        # apply the transform to the image and return it with the label\n",
    "        img, label = self.dataset[index]\n",
    "        return self.transform(img), label\n",
    "\n",
    "    def __len__(self):\n",
    "        # return the size of the dataset\n",
    "        return len(self.dataset)\n",
    "        \n",
    "# Load the dataset\n",
    "train_set = getattr(datasets, DATASET_NAME.upper())(root='./data', train=True, transform=None, download=True) # load train set without any transformations\n",
    "test_set = getattr(datasets, DATASET_NAME.upper())(root='./data', train=False, transform=val_test_transform, download=True) # load test set with transformations\n",
    "# randomly split train -> train, validation\n",
    "train_size = int(split_ratio * len(train_set))\n",
    "val_size = len(train_set) - train_size\n",
    "raw_train, raw_val = random_split(train_set, [train_size, val_size])\n",
    "\n",
    "# Apply transformations after splitting\n",
    "train_dataset = TransformedDataset(raw_train, train_transform) # apply train transformations\n",
    "val_dataset = TransformedDataset(raw_val, val_test_transform) # apply val/test transformtions\n",
    "\n",
    "# DataLoader for Training\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=True, \n",
    "                          persistent_workers=True\n",
    "                         )\n",
    "\n",
    "# DataLoader for Validation\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=False,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=True, \n",
    "                          persistent_workers=True\n",
    "                         )\n",
    "\n",
    "# DataLoader for Testing\n",
    "test_loader = DataLoader(test_set,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=False,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=True, \n",
    "                          persistent_workers=True\n",
    "                         )\n",
    "\n",
    "# Number of images in each DataLoader\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(f\"Number of imgaes in train_loader: {len(train_loader.dataset)}\") # train\n",
    "print(f\"Number of imgaes in val_loader: {len(val_loader.dataset)}\") # validation\n",
    "print(f\"Number of imgaes in test_loader: {len(test_loader.dataset)}\") # test\n",
    "print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816c8bf4-d24a-4bf2-a5d4-a511781d5e0e",
   "metadata": {},
   "source": [
    "# Setting Up the Model for Training in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5bd11b-0b3c-44c9-b767-791921c50c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamically get the model constructor\n",
    "model_fn = getattr(models, MODEL_NAME.lower())\n",
    "# Dynamically get the weights enum class\n",
    "weights_enum = getattr(models, weights_name)\n",
    "\n",
    "# Select a specific pretrained weight\n",
    "weights = weights_enum.IMAGENET1K_V1\n",
    "    \n",
    "# Load model with pretrained weights\n",
    "model = model_fn(weights=weights, progress=True).to(device)\n",
    "# Replace classification head\n",
    "model.heads = nn.Sequential(\n",
    "    nn.Linear(model.heads.head.in_features, NUM_CLASSES)\n",
    ")\n",
    "\n",
    "# Move the model to the specified device (GPU/CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# Unfreeze all layers for full fine-tuning\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cbdb28-db63-4d65-b354-6ab56208771a",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfa62f7-2225-42aa-8dba-3cea499021f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"           Model & Data Pipeline Summary\")\n",
    "print(\"=\"*60)\n",
    "# Print the model architecture for verification\n",
    "print(f\"Model Architecture:\\n{model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0057dca-90d4-4a9c-9698-6e8ac211a5a6",
   "metadata": {},
   "source": [
    "# Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd88e4c-88c5-4331-bdbd-1823eb36446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, train_loader, optimizer, criterion, device, ema):\n",
    "    model.train() # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # For the batch results logging frequency\n",
    "    num_batches = len(train_loader)\n",
    "    batch_print_interval = max(1, num_batches // 5)\n",
    "\n",
    "    # Training loop\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        # Move inputs and labels to the target device (CPU/GPU)\n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward Pass\n",
    "        outputs = model(inputs) # Output Shape=[batch_size,num_classes]\n",
    "        loss = criterion(outputs, labels) # Compute Loss\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        # Optimization - Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        ema.update()\n",
    "        \n",
    "        # Update running statistics\n",
    "        running_loss += loss.item() * inputs.size(0) # Aggregate batch Losses per epoch\n",
    "        predictions = outputs.argmax(dim=1) # Predicted classes\n",
    "        correct_predictions += (predictions == labels).sum().item() # Correct predictions\n",
    "        total_samples += inputs.size(0) # Aggregate Total Number of labels\n",
    "\n",
    "        # Per-batch logging\n",
    "        if batch_idx % batch_print_interval == 0:\n",
    "            batch_loss = loss.item()\n",
    "            batch_accuracy = (predictions == labels).sum().item() / inputs.size(0) * 100.0\n",
    "            print(f\"Batch {batch_idx+1}/{len(train_loader)} - \"\n",
    "                  f\"Batch Loss: {batch_loss:.6f}, Batch Accuracy: {batch_accuracy:.4f}%\")\n",
    "\n",
    "    # Calculate Training Loss and Accuracy for each epoch\n",
    "    train_loss = running_loss / total_samples # Compute Average Loss per sample\n",
    "    train_accuracy = correct_predictions / total_samples * 100.0 # Compute total accuracy for epoch\n",
    "\n",
    "    return train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce4dec8-1ea7-4cb2-9166-ce5b033f4a9b",
   "metadata": {},
   "source": [
    "# Validation / Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00a737c-e8e7-4da8-9d73-7c2f1500d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_test_loop(model, data_loader, criterion, device, compute_top5=False):\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions_top1 = 0 # Top1-predictions\n",
    "    correct_predictions_top5 = 0 # Top5-predictions\n",
    "    total_samples = 0\n",
    "\n",
    "    # Validation / Testing Loop\n",
    "    with torch.no_grad(): # Deatch gradients for validation\n",
    "        for inputs, labels in data_loader:\n",
    "            # Move inputs and labels to the target device (CPU/GPU)\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            # Forward Pass\n",
    "            outputs = model(inputs) # Output Shape=[batch_size,num_classes]\n",
    "            loss = criterion(outputs, labels) # Compute Loss\n",
    "\n",
    "            # Update running statistics for Top1-Accuracy\n",
    "            running_loss += loss.item() * inputs.size(0) # Aggregate batch Losses per epoch\n",
    "            predictions = outputs.argmax(dim=1) # Predicted classes\n",
    "            correct_predictions_top1 += (predictions == labels).sum().item() # Correct predictions\n",
    "            total_samples += inputs.size(0) # Aggregate Total Number of labels\n",
    "            \n",
    "            # For the Top5-Accuracy Calculation\n",
    "            if compute_top5:\n",
    "                _, top5_predictions = outputs.topk(5, dim=1)\n",
    "                correct_predictions_top5 += (top5_predictions == labels.unsqueeze(1)).any(dim=1).sum().item()\n",
    "\n",
    "    # Calculate Validation Loss and Accuracy for each epoch: Top1-Accuracy\n",
    "    avg_loss = running_loss / total_samples # Compute Average Loss per sample\n",
    "    top1_accuracy = correct_predictions_top1 / total_samples * 100.0 # Compute Top1-Accuracy\n",
    "    val_test_results = {\n",
    "        'top1_accuracy': top1_accuracy,\n",
    "        'loss': avg_loss,\n",
    "    }\n",
    "    \n",
    "    # Top5-Accuracy\n",
    "    if compute_top5:\n",
    "        top5_accuracy = correct_predictions_top5 / total_samples * 100.0\n",
    "        val_test_results['top5_accuracy'] = top5_accuracy\n",
    "\n",
    "    return val_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0871821f-1481-4fce-9014-2f856e80f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Callback(model):\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        model = model.module\n",
    "    with torch.no_grad():\n",
    "        E1_L1_weights = model.encoder.layers[0].mlp[0].weight\n",
    "        E1_L1_bias = model.encoder.layers[0].mlp[0].bias\n",
    "        for i in range(1, ALPHA * 2, 2):\n",
    "            E1_L1_weights[i].copy_(E1_L1_weights[i - 1])\n",
    "            E1_L1_bias[i].copy_(E1_L1_bias[i - 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae427128-40f8-40cf-89b2-1f3a313331cd",
   "metadata": {},
   "source": [
    "# Saving Result Metrics\n",
    "### Save Epoch Results \n",
    "* In a .csv and append data after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b394a287-3e4b-40f3-b734-50e91752b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_epoch_results(epoch, current_lr, running_train_loss, running_train_accuracy, val_loss, val_accuracy, KE_val_loss, KE_val_accuracy,\n",
    "                        epoch_time, KE_time, KE_with_V_time, FOLDER_NAME):\n",
    "    # Prepare the data for the current epoch\n",
    "    epoch_data = {\n",
    "        'Epoch': [epoch+1],\n",
    "        'LR' : [current_lr],\n",
    "        # Losses & Accuracies Before Callback\n",
    "        'Running Train Loss': [running_train_loss], \n",
    "        'Running Train Accuracy': [running_train_accuracy],\n",
    "        'Validation Loss': [val_loss],\n",
    "        'Validation Accuracy': [val_accuracy],\n",
    "        # Losses & Accuracies AFter Callback\n",
    "        'KE Validation Loss': [KE_val_loss],\n",
    "        'KE Validation Accuracy': [KE_val_accuracy],\n",
    "        # Time consumptions\n",
    "        'Epoch Time': [epoch_time],\n",
    "        'KE Time': [KE_time],\n",
    "        'KE + Forward Pass Time': [KE_with_V_time],\n",
    "    }\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(epoch_data)\n",
    "\n",
    "    # Define the file path where the results will be saved\n",
    "    file_path = os.path.join(FOLDER_NAME, f'{FOLDER_NAME}-a{ALPHA}-epoch_results.csv')\n",
    "    \n",
    "    # Check if the file exists, if not include header while saving\n",
    "    header = not os.path.exists(file_path)\n",
    "    \n",
    "    # Now, save+append the results to the CSV\n",
    "    df.to_csv(file_path, mode='a', header=header, index=False)\n",
    "\n",
    "    print(f\"Epoch {epoch} results saved...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82653f98-0270-4903-9b40-a2c376808c5b",
   "metadata": {},
   "source": [
    "## Checkpoint Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baf7382-0064-4ce1-861f-002cccd0f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, FOLDER_NAME):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }\n",
    "    # Define the checkpoint path (includes folder and filename)\n",
    "    checkpoint_path = os.path.join(FOLDER_NAME, f\"{FOLDER_NAME}-a{ALPHA}-checkpoint_epoch_{epoch+1}.pth\")\n",
    "    # Save the checkpoint\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"Checkpoint saved at epoch {epoch+1} to {checkpoint_path}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0029bb1d-0e76-4c1e-9f21-906913163ee4",
   "metadata": {},
   "source": [
    "## GPU & CPU monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e621fac6-d7d6-4d2d-82db-202896d6276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_gpu_info():\n",
    "    # Get the number of GPUs using PyTorch's CUDA device count\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    # Loop through each GPU (from 0 to num_gpus - 1)\n",
    "    for i in range(num_gpus):\n",
    "        handle = nvmlDeviceGetHandleByIndex(i)  # Get GPU device handle for the current GPU\n",
    "        # Retrieve memory information from the GPU\n",
    "        mem_info = nvmlDeviceGetMemoryInfo(handle)\n",
    "        # Retrieve GPU utilization information\n",
    "        gpu_util = nvmlDeviceGetUtilizationRates(handle)\n",
    "        # Retrieve GPU temperature information\n",
    "        gpu_temp = nvmlDeviceGetTemperature(handle, NVML_TEMPERATURE_GPU)\n",
    "        # Display GPU memory usage, utilization, and temperature for each GPU\n",
    "        print(f\"GPU {i}:\")\n",
    "        print(f\"  Memory Usage: {mem_info.used / 1024 ** 2} MB (Used) / {mem_info.total / 1024 ** 2} MB (Total)\")\n",
    "        print(f\"  GPU Utilization: {gpu_util.gpu} %\")\n",
    "        print(f\"  GPU Temperature: {gpu_temp} °C\")\n",
    "    # Check overall CPU and RAM usage\n",
    "    print(f\"CPU Usage: {psutil.cpu_percent()}%\")\n",
    "    print(f\"Memory Usage: {psutil.virtual_memory().percent}%\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948de08a-f0ff-4fa4-ab43-af162215f2c9",
   "metadata": {},
   "source": [
    "## Multi-GPU Training and Early Stopping in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0623f1d-54e2-4f86-9456-ea47390800cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataParallel allows splitting the input batch across multiple GPUs to speed up training.\n",
    "if torch.cuda.device_count() > 1:  # Check if more than one GPU is available\n",
    "    # Wrap the model with DataParallel to enable multi-GPU training\n",
    "    model = nn.DataParallel(model)  # This will distribute the input data across available GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924adf35-e6bf-4bc0-8651-7090e7bd7aea",
   "metadata": {},
   "source": [
    "# Training with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d80bfa-357e-42ec-9f02-d24be35913ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=0.05)\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "scheduler = CosineLRScheduler(\n",
    "    optimizer,\n",
    "    t_initial=num_epochs,\n",
    "    lr_min=1e-6,\n",
    "    warmup_t=5,\n",
    "    warmup_lr_init=1e-6,\n",
    "    warmup_prefix=True,\n",
    ")\n",
    "from torch_ema import ExponentialMovingAverage\n",
    "ema = ExponentialMovingAverage(model.parameters(), decay=0.9999)\n",
    "\n",
    "print(\"\\n\" + \"#\" * 60)\n",
    "print(f\"#         TRAINING STARTED: {MODEL_NAME} on {DATASET_NAME} Dataset        #\")\n",
    "print(\"#\" * 60 + \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"........... Epoch {epoch+1} Start - GPU & CPU monitoring ...........\")\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    summarize_gpu_info()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"...................... Epoch {epoch+1} Start .......................\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    running_train_loss, running_train_accuracy = train_loop(model, train_loader, optimizer, train_criterion, device, ema)\n",
    "\n",
    "    # with ema.average_parameters():\n",
    "    val_metrics = val_test_loop(model, val_loader, val_criterion, device)\n",
    "    val_loss = val_metrics['loss']\n",
    "    val_accuracy = val_metrics['top1_accuracy']\n",
    "    epoch_time = time.time() - epoch_start \n",
    "    \n",
    "    KE_start = time.time()\n",
    "    Callback(model)\n",
    "    KE_time = time.time() - KE_start\n",
    "    \n",
    "    KE_val_metrics = val_test_loop(model, val_loader, val_criterion, device)\n",
    "    KE_val_loss = KE_val_metrics['loss']\n",
    "    KE_val_accuracy = KE_val_metrics['top1_accuracy']\n",
    "    KE_with_V_time = time.time() - KE_start\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"...................... Epoch {epoch+1} Results .....................\")\n",
    "    print('--------------- Before Callback -----------------')\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} Summary:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Running Train Loss: {running_train_loss:.6f}, Running Train Accuracy: {running_train_accuracy:.4f}%\")\n",
    "    print(f\"Validation Loss: {val_loss:.6f}, Validation Accuracy: {val_accuracy:.4f}%\")\n",
    "\n",
    "    print('\\n---------------- After Callback -----------------')\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} Summary:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Validation Loss: {KE_val_loss:.6f}, Validation Accuracy: {KE_val_accuracy:.4f}%\")\n",
    "    \n",
    "    print(f\"\\n~~~*~~~ Time Consumptions ~~~*~~~\")\n",
    "    print(f\"Epoch {epoch+1} completed in {epoch_time/60:.4f} minutes.\")\n",
    "    print(f\"Time Consumption of Callback: {KE_time:.6f} seconds.\")\n",
    "    print(f\"Time Consumption of Callback + Forward Pass Validation dataset: {KE_with_V_time/60:.4f} minutes.\")\n",
    "    print(f\"Time Elapsed Since Epoch {epoch + 1} Started: {(time.time() - epoch_start)/60:.4f} minutes.\")\n",
    "    print(f\"Total Time Elapsed Since Training Started: {(time.time() - start_time)/60:.4f} minutes.\\n\")  \n",
    "        \n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    save_epoch_results(epoch, current_lr, running_train_loss, running_train_accuracy, val_loss, val_accuracy, KE_val_loss, KE_val_accuracy,\n",
    "                        epoch_time, KE_time, KE_with_V_time, FOLDER_NAME)\n",
    "\n",
    "    print(f\"\\n.........Epoch {epoch+1} End - GPU & CPU monitoring.........\")\n",
    "    summarize_gpu_info()\n",
    "\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        save_checkpoint(model, optimizer, epoch, FOLDER_NAME)\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        model_weights_path = os.path.join(FOLDER_NAME, f\"{FOLDER_NAME}-a{ALPHA}-best_model.pth\")\n",
    "        torch.save(model.state_dict(), model_weights_path)\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        \n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(\"\\n================ Early Stopping Triggered! =================\\n\")\n",
    "        break\n",
    "\n",
    "    scheduler.step(epoch)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"\\nTraining complete! Total time : {total_time:.4f} seconds.\")\n",
    "print(f\"                              : {total_time / 60:.4f} minutes.\")\n",
    "print(f\"                              : {total_time / 3600:.4f} hours.\")\n",
    "print(f\"                              : {total_time / 86400:.4f} days.\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n*~*~*~*~*~*~*~*~*~*~*~*~* THE END *~*~*~*~*~*~*~*~*~*~*~*~*~*\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "nvmlShutdown()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccc94bb-ea0f-46b6-b20d-f5f2bfbb8680",
   "metadata": {},
   "source": [
    "# Inferencing on Validation Dataset\n",
    "### Load the Model Structure and assign Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929e4921-db27-4bce-9ec3-88b5a418bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoupledNet Model\n",
    "Best_model = model_fn(weights=None, progress=True)\n",
    "# Replace the classification head\n",
    "Best_model.heads = nn.Sequential(\n",
    "    nn.Linear(Best_model.heads.head.in_features, NUM_CLASSES)\n",
    ")\n",
    "# Move to device\n",
    "Best_model = Best_model.to(device)\n",
    "\n",
    "# Wrap with DataParallel if using multiple GPUs\n",
    "if torch.cuda.device_count() > 1:\n",
    "    Best_model = nn.DataParallel(Best_model)\n",
    "\n",
    "# Load the model weights from the saved checkpoint\n",
    "weights_path = os.path.join(FOLDER_NAME, f\"{FOLDER_NAME}-a{ALPHA}-best_model.pth\")\n",
    "state_dict = torch.load(weights_path, map_location=device, weights_only=True)\n",
    "\n",
    "# Handle DataParallel/non-DataParallel key prefixes\n",
    "if any(key.startswith(\"module.\") for key in state_dict):\n",
    "    Best_model.load_state_dict(state_dict)\n",
    "else:\n",
    "    new_state_dict = {f\"module.{k}\": v for k, v in state_dict.items()}\n",
    "    Best_model.load_state_dict(new_state_dict)\n",
    "\n",
    "# Apply Callback to the reloaded model\n",
    "Callback(Best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0355826-22f8-45fe-899f-d4c027573727",
   "metadata": {},
   "source": [
    "### CoupledNet Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6d4d25-a919-429f-a427-f5d6149f01be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "Best_model.eval()\n",
    "test_metrics  = val_test_loop(Best_model, test_loader, val_criterion, device, compute_top5=True)\n",
    "\n",
    "# Print the final Validation loss and accuracy\n",
    "print('\\n')\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"######################## CoupledNet ########################\")\n",
    "print(\"------------- Inference on Validation Dataset --------------\")\n",
    "print(f\"Top-1 Accuracy: {test_metrics['top1_accuracy']:.4f}%, Top-5 Accuracy: {test_metrics['top5_accuracy']:.4f}%, Test Loss: {test_metrics['loss']:.6f}.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444069a8-828f-4207-a8dc-41949040db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the file\n",
    "log_file.close()\n",
    "\n",
    "# Reset stdout to default\n",
    "sys.stdout = sys.__stdout__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
