{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a23a0140-069f-4ad4-befc-c2555bc14391",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c46054-b2a7-42c3-b95a-3ec7068f9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch for tensor operations and building neural networks\n",
    "import torch\n",
    "# nn module provides essential tools for building neural networks\n",
    "import torch.nn as nn\n",
    "# optim module contains optimizers to train the model\n",
    "import torch.optim as optim\n",
    "# Datasets and pre-trained models from torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "# DataLoader is used to efficiently load data in batches during training\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "# For learning rate scheduling\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "# Display the model architecture summary\n",
    "from torchsummary import summary\n",
    "# tqdm is used to display progress bars during training or processes\n",
    "from tqdm import tqdm\n",
    "# numpy is used for numerical computations, such as arrays and matrices\n",
    "import numpy as np\n",
    "# pandas is used for data manipulation and analysis, often used with DataFrames\n",
    "import pandas as pd\n",
    "# matplotlib is used for plotting graphs and visualizing data\n",
    "import matplotlib.pyplot as plt\n",
    "# Used to measure training time or process durations\n",
    "import time\n",
    "# Import the random module to enable random number generation for various operations like shuffling or sampling\n",
    "import random\n",
    "# Import the os module for interacting with the operating system, including file system operations and environment variable access\n",
    "import os\n",
    "# interact with the Python runtime environment, including input/output redirection\n",
    "import sys\n",
    "# Python Imaging Library (PIL) to handle image loading and manipulation\n",
    "from PIL import Image\n",
    "# Importing required types from the typing module\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "# Import necessary libraries for resource monitoring\n",
    "import psutil  # For CPU and Memory usage monitoring\n",
    "import gc  # For garbage collection\n",
    "from pynvml import *  # NVIDIA GPU monitoring library\n",
    "\n",
    "torch.cuda.empty_cache()  # Clear unused memory\n",
    "\n",
    "# Initialize the NVIDIA Management Library (NVML)\n",
    "nvmlInit()  # This initializes the NVML library for GPU monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db12cab8-36c3-479b-aba6-f7d1cc18a156",
   "metadata": {},
   "source": [
    "#### Redirecting Print Output to a Log File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f68d6-132b-49a1-b014-ac814bc8f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder to save the Results\n",
    "folder_name = \"AlexNet-ImageNet Results_PURE\"\n",
    "\n",
    "# Check if the folder exists, if not create it\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# Save the log file in the specified folder\n",
    "log_file_path = os.path.join(folder_name, 'AlexNet_ImageNet-logfile.txt')\n",
    "log_file = open(log_file_path, 'w')\n",
    "\n",
    "# Redirect the standard output to the file\n",
    "sys.stdout = log_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ff515a-b9d2-4f29-a197-902b1f1805fa",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacdc583-f47c-4777-b87c-d5249b79712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define seed value\n",
    "seed = 42\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(seed)  # Python's random module\n",
    "np.random.seed(seed)  # NumPy random module\n",
    "torch.manual_seed(seed)  # PyTorch CPU random seed\n",
    "torch.cuda.manual_seed(seed)  # PyTorch GPU random seed (for current device)\n",
    "torch.cuda.manual_seed_all(seed)  # PyTorch GPU random seed (for all devices, if multi-GPU)\n",
    "\n",
    "# For deterministic behavior with cuDNN (when using GPU)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False  # Disables the cudnn autotuner to ensure reproducibility\n",
    "\n",
    "# Check if CUDA is available and set the seed for CUDA as well\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Check the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'{device} is available...')\n",
    "# Get the number of GPUs (if any) available using PyTorch\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of GPUs available: {num_gpus}\")\n",
    "# If GPUs are available, print the name of the first GPU\n",
    "if num_gpus > 0:\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\\n\")  # Print the name of the first GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1f66e0-6dcb-4d68-9534-84407e38dea2",
   "metadata": {},
   "source": [
    "## GPU & CPU monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a3beb-9c67-496c-ab1e-a22983675c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_gpu_info():\n",
    "    # Get the number of GPUs using PyTorch's CUDA device count\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "\n",
    "    # Loop through each GPU (from 0 to num_gpus - 1)\n",
    "    for i in range(num_gpus):\n",
    "        handle = nvmlDeviceGetHandleByIndex(i)  # Get GPU device handle for the current GPU\n",
    "        # Retrieve memory information from the GPU\n",
    "        mem_info = nvmlDeviceGetMemoryInfo(handle)\n",
    "        # Retrieve GPU utilization information\n",
    "        gpu_util = nvmlDeviceGetUtilizationRates(handle)\n",
    "        # Retrieve GPU temperature information\n",
    "        gpu_temp = nvmlDeviceGetTemperature(handle, NVML_TEMPERATURE_GPU)\n",
    "\n",
    "        # Display GPU memory usage, utilization, and temperature for each GPU\n",
    "        print(f\"GPU {i}:\")\n",
    "        print(f\"  Memory Usage: {mem_info.used / 1024 ** 2} MB (Used) / {mem_info.total / 1024 ** 2} MB (Total)\")\n",
    "        print(f\"  GPU Utilization: {gpu_util.gpu} %\")\n",
    "        print(f\"  GPU Temperature: {gpu_temp} Â°C\")\n",
    "\n",
    "    # Check overall CPU and RAM usage\n",
    "    print(f\"CPU Usage: {psutil.cpu_percent()}%\")\n",
    "    print(f\"Memory Usage: {psutil.virtual_memory().percent}%\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c43a6f-9479-474d-a566-ce787c960e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to summarize GPU and system information\n",
    "print(f\"...............Initial - GPU & CPU monitoring...............\")\n",
    "summarize_gpu_info()\n",
    "print(\"\\n\")\n",
    "# Trigger garbage collection\n",
    "gc.collect()  # Explicitly call garbage collection to clean up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35eba58-abe7-4a80-b3df-e9162019358d",
   "metadata": {},
   "source": [
    "# Setting Up an AlexNet Model for Training in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af16cb29-3e1f-47f9-bfb9-dab3369fff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AlexNet model without pre-trained weights and with 1000 output classes\n",
    "model = models.alexnet(weights=None, num_classes=1000).to(device) \n",
    "# Move the model to the specified device (GPU/CPU)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511dfee3-af53-4fc6-a512-195cba5952eb",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b055cc0c-25b3-4426-838d-1001a69ce4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model architecture for verification\n",
    "print(f\"Model Architecture:\\n{model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32b1a13-5b9a-47fb-b682-05c00220eeae",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd8f2c-59d0-4740-872f-32fbdcf054bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a summary of the model\n",
    "print(\"\\nModel Summary:\")\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf0260f-d07a-4a67-a243-c042362de536",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada1b5e-bcab-460a-81a6-d8ea7e4aeed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128  # Number of samples per batch; larger sizes speed up training but require more memory\n",
    "num_epochs = 300   # Number of times to iterate over the entire training dataset\n",
    "learning_rate = 0.01  # Controls how much the model's weights are updated during training\n",
    "\n",
    "# Early stopping parameters to prevent overfitting\n",
    "patience = 35  # Stop training if validation loss doesn't improve for 'patience' epochs\n",
    "best_val_loss = float('inf')  # Track the best validation loss encountered during training\n",
    "epochs_without_improvement = 0  # Counter to monitor no improvement in validation loss\n",
    "\n",
    "# Data loading parameters\n",
    "num_workers = 16  # Number of subprocesses for data loading\n",
    "\n",
    "# Define the loss function used to train the model.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Define the optimizer used to update model parameters.\n",
    "# The learning rate controls how large the model's weight updates are during training.\n",
    "# Momentum helps accelerate gradients vectors in the right directions, thus speeding up convergence.\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0005)\n",
    "# Set up the scheduler\n",
    "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)  # Set scheduler to reduce learning rate by 0.1 every 30 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b49421-e88f-4817-82bc-612b5802e9f5",
   "metadata": {},
   "source": [
    "# Data Augmentation and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f0c871-e1a6-4fad-b86e-af05a48d9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for ImageNet\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),  # Random crop and resize to 224x224 to fit AlexNet\n",
    "    transforms.RandomHorizontalFlip(), # Random horizontal flip\n",
    "    transforms.ToTensor(), # Convert PIL image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize ImageNet images using its mean and standard deviation\n",
    "])\n",
    "\n",
    "# Transformations for ImageNet test and validation datasets (no augmentation)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256), # Resize the image to 256 pixels on the shorter side\n",
    "    transforms.CenterCrop(224), # Then crop a 224x224 center crop\n",
    "    transforms.ToTensor(), # Convert PIL image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize ImageNet images using its mean and standard deviation\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ece090a-8f93-4035-96f7-cc03b5766e88",
   "metadata": {},
   "source": [
    "# Load ImageNet\n",
    "* Split into Training,Testing & Validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6ba27-0f74-4785-8f68-48c04e524946",
   "metadata": {},
   "source": [
    "### Custom Dataset Class for Loading Validation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dcaf0b-341b-4826-a894-e7b83d4f8a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validation_Image_Dataset(Dataset):\n",
    "    def __init__(self, targ_dir: str, annotation_file: str, transform=None) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            targ_dir (str): Directory where images are stored.\n",
    "            annotation_file (str): Path to the .txt file containing image filenames and class labels.\n",
    "            transform (callable, optional): A function/transform to apply to each image.\n",
    "        \"\"\"\n",
    "        self.targ_dir = targ_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Read the annotations file and store the mapping\n",
    "        self.image_paths = []\n",
    "        self.class_names = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Read annotation file and prepare data\n",
    "        with open(annotation_file, 'r') as f:\n",
    "            for line in f:\n",
    "                img_name, class_name, class_idx = line.strip().split(', ')\n",
    "                img_path = os.path.join(targ_dir, img_name)\n",
    "                self.image_paths.append(img_path)\n",
    "                self.class_names.append(class_name)\n",
    "                self.labels.append(int(class_idx))\n",
    "        \n",
    "        # Create a sorted list of unique class names (self.classes)\n",
    "        self.classes = sorted(set(self.class_names))\n",
    "        \n",
    "        # Create a mapping of class names to indices (class_to_idx)\n",
    "        self.class_to_idx = {class_name: idx for idx, class_name in enumerate(self.classes)}\n",
    "        \n",
    "        # Prepare imgs as a list of tuples (image_path, label)\n",
    "        self.imgs = [(self.image_paths[i], self.labels[i]) for i in range(len(self.image_paths))]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Returns the total number of samples.\"\"\"\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"\"\"Returns one sample of data (image and label).\"\"\"\n",
    "        img_path = self.image_paths[index]\n",
    "        img = Image.open(img_path).convert('RGB')  # Ensure image is in RGB format\n",
    "        \n",
    "        label = self.labels[index]\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8968b6-2c6d-4a5f-9de6-fefeba93544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training, validation, testing data paths directly in the current directory\n",
    "TRAIN_DIR = os.path.join('data', 'train', 'unzipped_1000')\n",
    "VALID_DIR = os.path.join('data', 'val')\n",
    "TEST_DIR = os.path.join('data', 'test')\n",
    "\n",
    "# Print the paths to confirm\n",
    "print(f\"\\n\\nTraining data path: {TRAIN_DIR}\")\n",
    "print(f\"Validation data path: {VALID_DIR}\")\n",
    "print(f\"Test data path: {TEST_DIR}\")\n",
    "\n",
    "# Load ImageNet dataset \n",
    "train_dataset = datasets.ImageFolder(root=TRAIN_DIR, transform=train_transform) # Train set with transformations\n",
    "val_dataset = Validation_Image_Dataset(targ_dir=VALID_DIR, annotation_file='data/val_annotation.txt', transform=val_transform) # Validation set with transformations\n",
    "\n",
    "# Create DataLoader for training\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=batch_size,  # Number of samples per batch\n",
    "                          shuffle=True,           # Shuffle dataset at each epoch\n",
    "                          num_workers=num_workers, # Number of subprocesses for data loading\n",
    "                          pin_memory=True)        # Pin memory for faster data transfer to GPU\n",
    "\n",
    "# Create DataLoader for validation\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                        batch_size=batch_size,  # Same batch size as training\n",
    "                        shuffle=False,          # No shuffling for validation\n",
    "                        num_workers=num_workers, # Number of subprocesses for validation\n",
    "                        pin_memory=True)        # Pin memory for faster data transfer\n",
    "\n",
    "# Check number of images in each DataLoader\n",
    "print(f\"\\nNumber of images in train_loader: {len(train_loader.dataset)}\") # Number of images in training dataset\n",
    "print(f\"Number of images in val_loader: {len(val_loader.dataset)}\") # Number of images in validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa79b372-4962-4655-981b-80fecc74024b",
   "metadata": {},
   "source": [
    "# Multi-GPU Training and Early Stopping in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644347c5-da22-4339-aec3-6222a5eec251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if multiple GPUs are available and use DataParallel for parallel training\n",
    "# DataParallel allows splitting the input batch across multiple GPUs to speed up training.\n",
    "# This is useful for larger models or when have access to a multi-GPU setup.\n",
    "if torch.cuda.device_count() > 1:  # Check if more than one GPU is available\n",
    "    # Wrap the model with DataParallel to enable multi-GPU training\n",
    "    model = nn.DataParallel(model)  # This will distribute the input data across available GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f9715-e115-4e74-aaa0-e29c157fc7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Callback(model):\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        model = model.module\n",
    "    with torch.no_grad():\n",
    "        conv1_weights = model.features[0].weight\n",
    "        conv1_bias = model.features[0].bias\n",
    "        for i in range(1, conv1_weights.size(0), 2):\n",
    "            conv1_weights[i].copy_(conv1_weights[i - 1])\n",
    "            conv1_bias[i].copy_(conv1_bias[i - 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7fc58e-8b8d-491d-9d99-45b4593930be",
   "metadata": {},
   "source": [
    "## Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09befed1-3cf4-4d65-b9bf-d2b29d41b8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, train_loader, optimizer, criterion, device):\n",
    "    print(f\"\\n~~~*~~~ Batch Summary ~~~*~~~\")\n",
    "    model.train() # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Taining Loop\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        # Move inputs and labels to the target device (GPU/CPU)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward Pass\n",
    "        outputs = model(inputs) # Output shape=[batch_size, num_classes]\n",
    "        loss = criterion(outputs, labels) # Compute Loss\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad() # Zero the parameter gradients\n",
    "        loss.backward() # Backpropagation\n",
    "        optimizer.step() # Update parameters\n",
    "\n",
    "        # Update running statistics\n",
    "        running_loss += loss.item() # Aggregate batch Losses per epoch\n",
    "        predictions = outputs.argmax(dim=1) # Predicted classes\n",
    "        correct_predictions += (predictions == labels).sum().item() # Actual and Predicted labels\n",
    "        total_samples += labels.size(0) # Aggregate Total Number of labels\n",
    "\n",
    "        # Batch-wise Information (Loss and Accuracy)\n",
    "        if batch_idx % 2000 == 0:  # Print every 2000 batches information\n",
    "            batch_loss = loss.item()\n",
    "            batch_accuracy = 100 * (predictions == labels).sum().item() / labels.size(0)\n",
    "            print(f\"Batch {batch_idx+1}/{len(train_loader)} - \"\n",
    "                  f\"Batch Loss: {batch_loss:.4f}, Batch Accuracy: {batch_accuracy:.2f}%\")\n",
    "\n",
    "    # Calculate Training loss and Accuracy for the epoch\n",
    "    train_loss = running_loss / len(train_loader)  # Compute Average loss per batch\n",
    "    train_accuracy = 100 * correct_predictions / total_samples # Compute Total accuracy for the epoch\n",
    "\n",
    "    return train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732092aa-33c7-4d9b-8024-6aba2aea4377",
   "metadata": {},
   "source": [
    "## Validation Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8585902-78d7-422c-8ce8-123030a9b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_test_loop(model, data_loader, criterion, device):\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Validation Loop\n",
    "    with torch.no_grad(): # Detach gradients for Validation\n",
    "        for inputs, labels in data_loader:\n",
    "            # Move inputs and labels to the target device (GPU/CPU)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "    \n",
    "            # Forward Pass\n",
    "            outputs = model(inputs) # Output shape=[batch_size, num_classes]\n",
    "            loss += criterion(outputs, labels).item() # Compute Loss and Aggregate\n",
    "    \n",
    "            # Update running statistics\n",
    "            predictions = outputs.argmax(dim=1) # Predicted classes\n",
    "            correct_predictions += (predictions == labels).sum().item() # Actual and Predicted labels\n",
    "            total_samples += labels.size(0) # Aggregate Total Number of labels\n",
    "\n",
    "    # Calculate Average Validation loss and Accuracy for the epoch\n",
    "    total_loss = loss / len(data_loader)  # Compute Average loss per batch\n",
    "    total_accuracy = 100 * correct_predictions / total_samples # Compute Total accuracy for the epoch\n",
    "\n",
    "    return total_loss, total_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbda593-c349-4a0b-9e42-f4c3918698aa",
   "metadata": {},
   "source": [
    "# Saving AlexNet Metrics on ImageNet\n",
    "### Save Epoch Results \n",
    "* In a .csv and append data after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67969695-acb9-409a-813b-59343b749ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_epoch_results(epoch, running_train_loss, running_train_accuracy, val_loss, val_accuracy, epoch_time, folder_name):\n",
    "    # Prepare the data for the current epoch\n",
    "    epoch_data = {\n",
    "        'Epoch': [epoch+1],\n",
    "        # Losses & Accuracies\n",
    "        'Running Train Loss': [running_train_loss], \n",
    "        'Running Train Accuracy': [running_train_accuracy],\n",
    "        'Validation Loss': [val_loss],\n",
    "        'Validation Accuracy': [val_accuracy],\n",
    "        # Time consumptions\n",
    "        'Epoch Time': [epoch_time],\n",
    "    }\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(epoch_data)\n",
    "\n",
    "    # Define the file path where the results will be saved\n",
    "    file_path = os.path.join(folder_name, 'epoch_results.csv')\n",
    "    \n",
    "    # Check if the file exists, if not include header while saving\n",
    "    header = not os.path.exists(file_path)\n",
    "    \n",
    "    # Now, save+append the results to the CSV\n",
    "    df.to_csv(file_path, mode='a', header=header, index=False)\n",
    "\n",
    "    print(f\"Epoch {epoch} results saved...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39835ae6-cad3-43ec-8a86-7f833643f5e8",
   "metadata": {},
   "source": [
    "## Checkpoint Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124d48d5-1875-4a58-9cfb-9cf3e55f8f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, folder_name):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }\n",
    "    # Define the checkpoint path (includes folder and filename)\n",
    "    checkpoint_path = os.path.join(folder_name, f\"checkpoint_epoch_{epoch+1}.pth\")\n",
    "    # Save the checkpoint\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"Checkpoint saved at epoch {epoch+1} to {checkpoint_path}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e0dcf0-72b1-4f4d-b57e-3920e7d39147",
   "metadata": {},
   "source": [
    "# Training with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c85c6-153e-4289-8f6c-21691e59b75a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"\\n.............Training Start - GPU & CPU monitoring..............\")\n",
    "summarize_gpu_info()\n",
    "print(\"\\n\")\n",
    "gc.collect()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"    Training Started on AlexNet using ImageNet Dataset    \")\n",
    "print(\"=\"*60)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Starting Epoch {epoch+1}/{num_epochs}...\\n{'-'*60}\")\n",
    "\n",
    "    print(f\"............Epoch {epoch+1} Start - GPU & CPU monitoring............\")\n",
    "    summarize_gpu_info()\n",
    "\n",
    "    running_train_loss, running_train_accuracy = train_loop(model, train_loader, optimizer, criterion, device)\n",
    "\n",
    "    val_loss, val_accuracy = val_test_loop(model, val_loader, criterion, device)\n",
    "\n",
    "    print('\\n---------------- Before Callback ----------------')\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} Summary:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Running Train Loss: {running_train_loss:.4f}, Running Train Accuracy: {running_train_accuracy:.2f}%\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    epoch_time = time.time() - epoch_start        \n",
    "    \n",
    "    print('\\n---------------- After Callback -----------------')\n",
    "\n",
    "    KE_start = time.time()\n",
    "    Callback(model)\n",
    "    KE_time = time.time() - KE_start\n",
    "    \n",
    "    KE_val_loss, KE_val_accuracy = val_test_loop(model, val_loader, criterion, device)\n",
    "    KE_with_V_time = time.time() - KE_start\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} Summary:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Validation Loss: {KE_val_loss:.4f}, Validation Accuracy: {KE_val_accuracy:.2f}%\")\n",
    "    \n",
    "    print(f\"\\n~~~*~~~ Time Consumptions ~~~*~~~\")\n",
    "    print(f\"Epoch {epoch+1} completed in {epoch_time/60:.4f} minutes.\")\n",
    "    print(f\"Time Consumption of Callback: {KE_time:.6f} seconds.\")\n",
    "    print(f\"Time Consumption of Callback + Forward Pass Validation dataset: {KE_with_V_time/60:.4f} minutes.\")\n",
    "    print(f\"Time Elapsed Since Epoch {epoch + 1} Started: {(time.time() - epoch_start)/60:.4f} minutes.\")\n",
    "    print(f\"Total Time Elapsed Since Training Started: {(time.time() - start_time)/60:.4f} minutes.\\n\")\n",
    "    \n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "    save_epoch_results(epoch, current_lr, running_train_loss, running_train_accuracy, val_loss, val_accuracy, KE_val_loss, KE_val_accuracy,\n",
    "                        epoch_time, KE_time, KE_with_V_time, folder_name)\n",
    "\n",
    "    print(f\"\\n.........Epoch {epoch+1} End - GPU & CPU monitoring.........\")\n",
    "    summarize_gpu_info()\n",
    "\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        save_checkpoint(model, optimizer, epoch, folder_name)\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        model_weights_path = os.path.join(folder_name, \"AlexNet_best-ImageNet.pth\")\n",
    "        torch.save(model.state_dict(), model_weights_path)\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        \n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(\"\\n================ Early Stopping Triggered! =================\\n\")\n",
    "        break\n",
    "\n",
    "    scheduler.step()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"\\nTraining complete! Total time: {total_time / 3600:.2f} hours.\")\n",
    "print(f\"                               : {total_time / 86400:.2f} days.\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n*~*~*~*~*~*~*~*~*~*~*~*~*~* THE END *~*~*~*~*~*~*~*~*~*~*~*~*~*\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "nvmlShutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2160123a-0199-4efc-987c-1f0051a47701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the file\n",
    "log_file.close()\n",
    "\n",
    "# Reset stdout to default\n",
    "sys.stdout = sys.__stdout__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
