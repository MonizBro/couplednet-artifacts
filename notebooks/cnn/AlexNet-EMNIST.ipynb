{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a23a0140-069f-4ad4-befc-c2555bc14391",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c46054-b2a7-42c3-b95a-3ec7068f9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch for tensor operations and building neural networks\n",
    "import torch\n",
    "# nn module provides essential tools for building neural networks\n",
    "import torch.nn as nn\n",
    "# optim module contains optimizers to train the model\n",
    "import torch.optim as optim\n",
    "# Datasets and pre-trained models from torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "# DataLoader is used to efficiently load data in batches during training\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "# For learning rate scheduling\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "# Display the model architecture summary\n",
    "from torchsummary import summary\n",
    "# tqdm is used to display progress bars during training or processes\n",
    "from tqdm import tqdm\n",
    "# numpy is used for numerical computations, such as arrays and matrices\n",
    "import numpy as np\n",
    "# pandas is used for data manipulation and analysis, often used with DataFrames\n",
    "import pandas as pd\n",
    "# matplotlib is used for plotting graphs and visualizing data\n",
    "import matplotlib.pyplot as plt\n",
    "# Used to measure training time or process durations\n",
    "import time\n",
    "# Import the random module to enable random number generation for various operations like shuffling or sampling\n",
    "import random\n",
    "# Import the os module for interacting with the operating system, including file system operations and environment variable access\n",
    "import os\n",
    "# interact with the Python runtime environment, including input/output redirection\n",
    "import sys\n",
    "# Python Imaging Library (PIL) to handle image loading and manipulation\n",
    "from PIL import Image\n",
    "# Importing required types from the typing module\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "# Import necessary libraries for resource monitoring\n",
    "import psutil  # For CPU and Memory usage monitoring\n",
    "import gc  # For garbage collection\n",
    "from pynvml import *  # NVIDIA GPU monitoring library\n",
    "\n",
    "torch.cuda.empty_cache()  # Clear unused memory\n",
    "\n",
    "# Initialize the NVIDIA Management Library (NVML)\n",
    "nvmlInit()  # This initializes the NVML library for GPU monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db12cab8-36c3-479b-aba6-f7d1cc18a156",
   "metadata": {},
   "source": [
    "#### Redirecting Print Output to a Log File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f68d6-132b-49a1-b014-ac814bc8f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main parameters\n",
    "MODEL = \"AlexNet\" # Target Model\n",
    "DATASET = \"EMNIST\" # Target Dataset\n",
    "NUM_CLASSES = 26 # No of classes\n",
    "ALPHA = 0 # Couplin Factor\n",
    "\n",
    "# Define the folder to save the Results\n",
    "FOLDER_NAME = f\"{MODEL}-{DATASET}\"\n",
    "# Check if the folder exists, if not create it\n",
    "if not os.path.exists(FOLDER_NAME):\n",
    "    os.makedirs(FOLDER_NAME)\n",
    "\n",
    "# Save the log file in the specified folder\n",
    "log_file_path = os.path.join(FOLDER_NAME, f\"{MODEL}_{DATASET}_a{ALPHA}-logfile.txt\")\n",
    "log_file = open(log_file_path, 'w')\n",
    "\n",
    "# Redirect the standard output to the file\n",
    "sys.stdout = log_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ff515a-b9d2-4f29-a197-902b1f1805fa",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacdc583-f47c-4777-b87c-d5249b79712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define seed value\n",
    "seed = 42\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(seed)  # Python's random module\n",
    "np.random.seed(seed)  # NumPy random module\n",
    "torch.manual_seed(seed)  # PyTorch CPU random seed\n",
    "# Check if CUDA is available and set the seed for CUDA as well\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)  # PyTorch GPU random seed (for current device)\n",
    "    torch.cuda.manual_seed_all(seed) # PyTorch GPU random seed (for all devices, if multi-GPU)\n",
    "\n",
    "# For deterministic behavior with cuDNN (when using GPU)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False  # Disables the cudnn autotuner to ensure reproducibility\n",
    "\n",
    "# Check the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'{device} is available...')\n",
    "# Get the number of GPUs (if any) available using PyTorch\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of GPUs available: {num_gpus}\")\n",
    "# If GPUs are available, print the name of the first GPU\n",
    "if num_gpus > 0:\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\\n\")  # Print the name of the first GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb021d75-da2e-476a-8191-b5dc418a986c",
   "metadata": {},
   "source": [
    "## GPU & CPU monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05953979-3bac-4d5f-8e3a-d2eb19031a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_gpu_info():\n",
    "    # Get the number of GPUs using PyTorch's CUDA device count\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "\n",
    "    # Loop through each GPU (from 0 to num_gpus - 1)\n",
    "    for i in range(num_gpus):\n",
    "        handle = nvmlDeviceGetHandleByIndex(i)  # Get GPU device handle for the current GPU\n",
    "        # Retrieve memory information from the GPU\n",
    "        mem_info = nvmlDeviceGetMemoryInfo(handle)\n",
    "        # Retrieve GPU utilization information\n",
    "        gpu_util = nvmlDeviceGetUtilizationRates(handle)\n",
    "        # Retrieve GPU temperature information\n",
    "        gpu_temp = nvmlDeviceGetTemperature(handle, NVML_TEMPERATURE_GPU)\n",
    "\n",
    "        # Display GPU memory usage, utilization, and temperature for each GPU\n",
    "        print(f\"GPU {i}:\")\n",
    "        print(f\"  Memory Usage: {mem_info.used / 1024 ** 2} MB (Used) / {mem_info.total / 1024 ** 2} MB (Total)\")\n",
    "        print(f\"  GPU Utilization: {gpu_util.gpu} %\")\n",
    "        print(f\"  GPU Temperature: {gpu_temp} Â°C\")\n",
    "\n",
    "    # Check overall CPU and RAM usage\n",
    "    print(f\"CPU Usage: {psutil.cpu_percent()}%\")\n",
    "    print(f\"Memory Usage: {psutil.virtual_memory().percent}%\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11024750-af7a-4761-a446-54ac5fabb03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to summarize GPU and system information\n",
    "print(f\"...............Initial - GPU & CPU monitoring...............\")\n",
    "summarize_gpu_info()\n",
    "print(\"\\n\")\n",
    "# Trigger garbage collection\n",
    "gc.collect()  # Explicitly call garbage collection to clean up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35eba58-abe7-4a80-b3df-e9162019358d",
   "metadata": {},
   "source": [
    "# Setting Up an AlexNet Model for Training in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af16cb29-3e1f-47f9-bfb9-dab3369fff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AlexNet model without pre-trained weights and with output classes\n",
    "model = models.alexnet(weights=None, num_classes=NUM_CLASSES).to(device) \n",
    "# Modify the first convolutional layer to accept grayscale images (1 input channel)\n",
    "model.features[0] = nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2)\n",
    "# Move the model to the specified device (GPU/CPU)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511dfee3-af53-4fc6-a512-195cba5952eb",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b055cc0c-25b3-4426-838d-1001a69ce4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"           Model & Data Pipeline Summary\")\n",
    "print(\"=\"*60)\n",
    "# Print the model architecture for verification\n",
    "print(f\"Model Architecture:\\n{model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32b1a13-5b9a-47fb-b682-05c00220eeae",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd8f2c-59d0-4740-872f-32fbdcf054bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a summary of the model\n",
    "print(\"\\n\\nModel Summary:\")\n",
    "summary(model, (1, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf0260f-d07a-4a67-a243-c042362de536",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada1b5e-bcab-460a-81a6-d8ea7e4aeed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "split_ratio = 0.85 # Split training set into 85% for training and 15% for validation\n",
    "batch_size = 128 # Number of samples per batch; larger sizes speed up training but require more memory\n",
    "num_epochs = 300 # Number of times to iterate over the entire training dataset\n",
    "learning_rate = 0.01 # Controls how much the model's weights are updated during training\n",
    "\n",
    "# Early stopping parameters to prevent overfitting\n",
    "patience = 15  # Stop training if validation loss doesn't improve for 'patience' epochs\n",
    "best_val_loss = float('inf')  # Track the best validation loss encountered during training\n",
    "epochs_without_improvement = 0  # Counter to monitor no improvement in validation loss\n",
    "\n",
    "# Data loading parameters\n",
    "num_workers = 16  # Number of subprocesses for data loading\n",
    "\n",
    "# Define the loss function used to train the model.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Define the optimizer used to update model parameters.\n",
    "# The learning rate controls how large the model's weight updates are during training.\n",
    "# Momentum helps accelerate gradients vectors in the right directions, thus speeding up convergence.\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)\n",
    "# Set up the scheduler\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)  # Example scheduler to reduce learning rate by 0.1 every 30 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b49421-e88f-4817-82bc-612b5802e9f5",
   "metadata": {},
   "source": [
    "# Data Augmentation and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f0c871-e1a6-4fad-b86e-af05a48d9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for MNIST\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(224), # Resize images to 224x224 to fit AlexNet\n",
    "    transforms.RandomHorizontalFlip(), # Random horizontal flip\n",
    "    transforms.RandomRotation(20), # Random rotation with a degree range (-20 to 20 degrees)\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=10), # Random affine transformation with translation, scaling, and shear\n",
    "    transforms.ToTensor(), # Convert PIL image to tensor\n",
    "    transforms.Normalize(mean=[0.17222732305526733], std=[0.3309466242790222]), # Normalize MNIST images using its mean and standard deviation\n",
    "])\n",
    "\n",
    "# Transformations for MNIST test and validation datasets (no augmentation)\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize(224), # Resize images to 224x224 to fit AlexNet\n",
    "    transforms.ToTensor(), # Convert PIL image to tensor\n",
    "    transforms.Normalize(mean=[0.17222732305526733], std=[0.3309466242790222]), # Normalize MNIST images using its mean and standard deviation\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ece090a-8f93-4035-96f7-cc03b5766e88",
   "metadata": {},
   "source": [
    "# Load MNIST\n",
    "* Split into Training,Testing & Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8968b6-2c6d-4a5f-9de6-fefeba93544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedDataset(Dataset):\n",
    "    def __init__(self, dataset, transform):\n",
    "        # Wrap an existing dataset and apply a transform to each image\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Apply the transform to the image and return it with the label\n",
    "        img, label = self.dataset[index]\n",
    "        return self.transform(img), label\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the size of the dataset\n",
    "        return len(self.dataset)\n",
    "\n",
    "# Load MNIST dataset \n",
    "train_set = datasets.EMNIST(root='./data', split='letters', train=True, download=True, transform=None) # Without any transformations (no augmentation)\n",
    "test_set = datasets.EMNIST(root='./data', split='letters', train=False, download=True, transform=val_test_transform)  # Test set with transformations\n",
    "\n",
    "# Split training set into p% for training and 1-p% for validation\n",
    "train_size = int(split_ratio * len(train_set))  # p% for training\n",
    "val_size = len(train_set) - train_size   # 1-p% for validation\n",
    "raw_train, raw_val = random_split(train_set, [train_size, val_size])  # Randomly split the dataset\n",
    "\n",
    "# Apply the transformations after splitting (for training and validation datasets)\n",
    "train_dataset = TransformedDataset(raw_train, train_transform)  # Apply train transformations to the training set\n",
    "val_dataset = TransformedDataset(raw_val, val_test_transform)  # Apply val/test transformations to the validation set\n",
    "\n",
    "# Create DataLoader for training\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=batch_size,  # Number of samples per batch\n",
    "                          shuffle=True,           # Shuffle dataset at each epoch\n",
    "                          num_workers=num_workers, # Number of subprocesses for data loading\n",
    "                          pin_memory=True)        # Pin memory for faster data transfer to GPU\n",
    "\n",
    "# Create DataLoader for validation\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                        batch_size=batch_size,  # Same batch size as training\n",
    "                        shuffle=False,          # No shuffling for validation\n",
    "                        num_workers=num_workers, # Number of subprocesses for validation\n",
    "                        pin_memory=True)        # Pin memory for faster data transfer\n",
    "\n",
    "# Create DataLoader for testing\n",
    "test_loader = DataLoader(test_set, \n",
    "                         batch_size=batch_size,  # Same batch size for testing\n",
    "                         shuffle=False,          # No shuffling for testing\n",
    "                         num_workers=num_workers, # Number of subprocesses for testing\n",
    "                         pin_memory=True)        # Pin memory for faster data transfer\n",
    "\n",
    "# Check number of images in each DataLoader\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(f\"Number of images in train_loader: {len(train_loader.dataset)}\") # Number of images in training dataset\n",
    "print(f\"Number of images in val_loader: {len(val_loader.dataset)}\") # Number of images in validation dataset\n",
    "print(f\"Number of images in test_loader: {len(test_loader.dataset)}\") # Number of images in testing dataset\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa79b372-4962-4655-981b-80fecc74024b",
   "metadata": {},
   "source": [
    "# Multi-GPU Training and Early Stopping in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644347c5-da22-4339-aec3-6222a5eec251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if multiple GPUs are available and use DataParallel for parallel training\n",
    "# DataParallel allows splitting the input batch across multiple GPUs to speed up training.\n",
    "# This is useful for larger models or when have access to a multi-GPU setup.\n",
    "if torch.cuda.device_count() > 1:  # Check if more than one GPU is available\n",
    "    # Wrap the model with DataParallel to enable multi-GPU training\n",
    "    model = nn.DataParallel(model)  # This will distribute the input data across available GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f9715-e115-4e74-aaa0-e29c157fc7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Equalize_Filters(model):\n",
    "    if isinstance(model, nn.DataParallel):\n",
    "        model = model.module\n",
    "    with torch.no_grad():\n",
    "        conv1_weights = model.features[0].weight\n",
    "        conv1_bias = model.features[0].bias\n",
    "        for i in range(1, ALPHA * 2, 2):\n",
    "            conv1_weights[i].copy_(conv1_weights[i - 1])\n",
    "            conv1_bias[i].copy_(conv1_bias[i - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7fc58e-8b8d-491d-9d99-45b4593930be",
   "metadata": {},
   "source": [
    "## Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09befed1-3cf4-4d65-b9bf-d2b29d41b8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, train_loader, optimizer, criterion, device):\n",
    "    model.train() # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Taining Loop\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        # Move inputs and labels to the target device (GPU/CPU)\n",
    "        inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "        # Subtract 1 from the target values to shift them to the range 0-25\n",
    "        labels = (labels - 1).to(device)\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward Pass\n",
    "        outputs = model(inputs) # Output shape=[batch_size, num_classes]\n",
    "        loss = criterion(outputs, labels) # Compute Loss\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        loss.backward() # Backpropagation\n",
    "        optimizer.step() # Update parameters\n",
    "\n",
    "        # Update running statistics\n",
    "        running_loss += loss.item() * inputs.size(0) # Aggregate batch Losses per epoch\n",
    "        predictions = outputs.argmax(dim=1) # Predicted classes\n",
    "        correct_predictions += (predictions == labels).sum().item() # Actual and Predicted labels\n",
    "        total_samples += labels.size(0) # Aggregate Total Number of labels\n",
    "        \n",
    "        # Batch-wise Information (Loss and Accuracy)\n",
    "        num_batches = len(train_loader)\n",
    "        batch_print_interval = max(1, num_batches // 5)\n",
    "        if batch_idx % batch_print_interval == 0:  # Print logic for batch information\n",
    "            batch_loss = loss.item()\n",
    "            batch_accuracy = 100 * correct_predictions / total_samples\n",
    "            print(f\"Batch {batch_idx+1}/{len(train_loader)} - Batch Loss: {batch_loss:.6f}, Batch Accuracy: {batch_accuracy:.4f}%\")\n",
    "\n",
    "    # Calculate Training loss and Accuracy for the epoch\n",
    "    train_loss = running_loss / total_samples # Compute Average loss per batch\n",
    "    train_accuracy = 100 * correct_predictions / total_samples # Compute Total accuracy for the epoch\n",
    "\n",
    "    return train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732092aa-33c7-4d9b-8024-6aba2aea4377",
   "metadata": {},
   "source": [
    "## Validation / Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8585902-78d7-422c-8ce8-123030a9b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_test_loop(model, data_loader, criterion, device):\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Validation Loop\n",
    "    with torch.no_grad(): # Detach gradients for Validation\n",
    "        for inputs, labels in data_loader:\n",
    "            # Move inputs and labels to the target device (GPU/CPU)\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            # Subtract 1 from the target values to shift them to the range 0-25\n",
    "            labels = (labels - 1).to(device)\n",
    "            # Forward Pass\n",
    "            outputs = model(inputs) # Output shape=[batch_size, num_classes]\n",
    "            loss += criterion(outputs, labels).item() * inputs.size(0) # Compute Loss and Aggregate\n",
    "    \n",
    "            # Update running statistics\n",
    "            predictions = outputs.argmax(dim=1) # Predicted classes\n",
    "            correct_predictions += (predictions == labels).sum().item()\n",
    "            total_samples += labels.size(0) # Aggregate Total Number of labels\n",
    "\n",
    "    # Calculate Average Validation loss and Accuracy for the epoch\n",
    "    total_loss = loss / total_samples  # Compute Average loss per batch\n",
    "    total_accuracy = 100 * correct_predictions / total_samples # Compute Total accuracy for the epoch\n",
    "\n",
    "    return total_loss, total_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c90ed27-837e-4fb5-a9e8-e6e9897abc49",
   "metadata": {},
   "source": [
    "# Saving AlexNet Metrics on ImageNet\n",
    "### Save Epoch Results \n",
    "* In a .csv and append data after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2a3e6-76fe-4dfe-96d5-08693f563656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_epoch_results(epoch, current_lr, running_train_loss, running_train_accuracy, val_loss, val_accuracy, KE_val_loss, KE_val_accuracy,\n",
    "                        epoch_time, KE_time, KE_with_V_time, FOLDER_NAME):\n",
    "    # Prepare the data for the current epoch\n",
    "    epoch_data = {\n",
    "        'Epoch': [epoch+1],\n",
    "        'LR' : [current_lr],\n",
    "        # Losses & Accuracies Before Kernel Equalization\n",
    "        'Running Train Loss': [running_train_loss], \n",
    "        'Running Train Accuracy': [running_train_accuracy],\n",
    "        'Validation Loss': [val_loss],\n",
    "        'Validation Accuracy': [val_accuracy],\n",
    "        # Losses & Accuracies AFter Kernel Equalization\n",
    "        'KE Validation Loss': [KE_val_loss],\n",
    "        'KE Validation Accuracy': [KE_val_accuracy],\n",
    "        # Time consumptions\n",
    "        'Epoch Time': [epoch_time],\n",
    "        'KE Time': [KE_time],\n",
    "        'KE + Forward Pass Time': [KE_with_V_time],\n",
    "    }\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(epoch_data)\n",
    "\n",
    "    # Define the file path where the results will be saved\n",
    "    file_path = os.path.join(FOLDER_NAME, f'{FOLDER_NAME}-a{ALPHA}-epoch_results.csv')\n",
    "    \n",
    "    # Check if the file exists, if not include header while saving\n",
    "    header = not os.path.exists(file_path)\n",
    "    \n",
    "    # Now, save+append the results to the CSV\n",
    "    df.to_csv(file_path, mode='a', header=header, index=False)\n",
    "\n",
    "    print(f\"Epoch {epoch} results saved...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c351643-c8b1-4b13-a3a9-a25059703493",
   "metadata": {},
   "source": [
    "## Checkpoint Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9a40df-6936-4865-b072-826a9b7bc44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, FOLDER_NAME):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }\n",
    "    # Define the checkpoint path (includes folder and filename)\n",
    "    checkpoint_path = os.path.join(FOLDER_NAME, f\"{FOLDER_NAME}-a{ALPHA}-checkpoint_epoch_{epoch+1}.pth\")\n",
    "    # Save the checkpoint\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"Checkpoint saved at epoch {epoch+1} to {checkpoint_path}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e0dcf0-72b1-4f4d-b57e-3920e7d39147",
   "metadata": {},
   "source": [
    "# Training with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c85c6-153e-4289-8f6c-21691e59b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"#\" * 60)\n",
    "print(f\"#         TRAINING STARTED: {MODEL} on {DATASET} Dataset        #\")\n",
    "print(\"#\" * 60 + \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"........... Epoch {epoch+1} Start - GPU & CPU monitoring ...........\")\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    summarize_gpu_info()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"...................... Epoch {epoch+1} Start .......................\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    running_train_loss, running_train_accuracy = train_loop(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_accuracy = val_test_loop(model, val_loader, criterion, device)\n",
    "    epoch_time = time.time() - epoch_start \n",
    "    \n",
    "    KE_start = time.time()\n",
    "    Equalize_Filters(model)\n",
    "    KE_time = time.time() - KE_start\n",
    "    \n",
    "    KE_val_loss, KE_val_accuracy = val_test_loop(model, val_loader, criterion, device)\n",
    "    KE_with_V_time = time.time() - KE_start\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"...................... Epoch {epoch+1} Results .....................\")\n",
    "    print('--------------- Before Kernel Equalization -----------------')\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} Summary:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Running Train Loss: {running_train_loss:.6f}, Running Train Accuracy: {running_train_accuracy:.4f}%\")\n",
    "    print(f\"Validation Loss: {val_loss:.6f}, Validation Accuracy: {val_accuracy:.4f}%\")\n",
    "\n",
    "    print('\\n---------------- After Kernel Equalization -----------------')\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} Summary:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Validation Loss: {KE_val_loss:.6f}, Validation Accuracy: {KE_val_accuracy:.4f}%\")\n",
    "    \n",
    "    print(f\"\\n~~~*~~~ Time Consumptions ~~~*~~~\")\n",
    "    print(f\"Epoch {epoch+1} completed in {epoch_time/60:.4f} minutes.\")\n",
    "    print(f\"Time Consumption of Kernel Equalization: {KE_time:.6f} seconds.\")\n",
    "    print(f\"Time Consumption of Kernel Equalization + Forward Pass Validation dataset: {KE_with_V_time/60:.4f} minutes.\")\n",
    "    print(f\"Time Elapsed Since Epoch {epoch + 1} Started: {(time.time() - epoch_start)/60:.4f} minutes.\")\n",
    "    print(f\"Total Time Elapsed Since Training Started: {(time.time() - start_time)/60:.4f} minutes.\\n\")  \n",
    "        \n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "\n",
    "    save_epoch_results(epoch, current_lr, running_train_loss, running_train_accuracy, val_loss, val_accuracy, KE_val_loss, KE_val_accuracy,\n",
    "                        epoch_time, KE_time, KE_with_V_time, FOLDER_NAME)\n",
    "\n",
    "    print(f\"\\n.........Epoch {epoch+1} End - GPU & CPU monitoring.........\")\n",
    "    summarize_gpu_info()\n",
    "\n",
    "    if (epoch + 1) % 30 == 0:\n",
    "        save_checkpoint(model, optimizer, epoch, FOLDER_NAME)\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        model_weights_path = os.path.join(FOLDER_NAME, f\"{FOLDER_NAME}-a{ALPHA}-best_model.pth\")\n",
    "        torch.save(model.state_dict(), model_weights_path)\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        \n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(\"\\n================ Early Stopping Triggered! =================\\n\")\n",
    "        break\n",
    "\n",
    "    scheduler.step()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "\n",
    "print(f\"\\nTraining complete! Total time: {total_time / 60:.4f} minutes.\")\n",
    "print(f\"                             : {total_time / 3600:.4f} hours.\")\n",
    "print(f\"                             : {total_time / 86400:.4f} days.\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n*~*~*~*~*~*~*~*~*~*~*~*~* THE END *~*~*~*~*~*~*~*~*~*~*~*~*~*\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "nvmlShutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c42e7c-8cd7-42e4-9004-8cc38253fbdd",
   "metadata": {},
   "source": [
    "# Load the Model Structure and assign Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8009bac8-5727-4a46-9a70-18e88794f695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoupledNet Model\n",
    "Best_model = models.alexnet(weights=None, num_classes=NUM_CLASSES) # Load AlexNet model without pre-trained weights and with output classes\n",
    "Best_model.features[0] = nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2)\n",
    "Best_model = Best_model.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    Best_model = nn.DataParallel(Best_model) # Only wrap DDP if multi-GPU\n",
    "    \n",
    "# Load the model and weights\n",
    "weights_path = os.path.join(FOLDER_NAME, f\"{FOLDER_NAME}-a{ALPHA}-best_model.pth\")  # Adjust this path to the correct file\n",
    "state_dict = torch.load(weights_path, weights_only=True)\n",
    "\n",
    "new_state_dict = {}\n",
    "if any(key.startswith(\"module.\") for key in state_dict.keys()):\n",
    "    # All keys have module. prefix\n",
    "    new_state_dict = state_dict\n",
    "else:\n",
    "    # Add module. prefix if missing (needed for DataParallel)\n",
    "    for key, value in state_dict.items():\n",
    "        new_state_dict[\"module.\" + key] = value\n",
    "\n",
    "Best_model.load_state_dict(new_state_dict)\n",
    "\n",
    "# Equalize filters\n",
    "Equalize_Filters(Best_model)\n",
    "\n",
    "# Reverse Engineering model\n",
    "RE_model = models.alexnet(weights=None, num_classes=NUM_CLASSES)\n",
    "RE_model.features[0] = nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2)\n",
    "RE_model = RE_model.to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    RE_model = nn.DataParallel(RE_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c2fc43-3512-4258-a571-288f499fd383",
   "metadata": {},
   "source": [
    "# top-1 Accuracy & top-5 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf2f99-f6a0-4020-b687-a3392b237e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_accuracy(model, data_loader, criterion, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    loss = 0.0\n",
    "    correct_predictions_top1 = 0\n",
    "    correct_predictions_top5 = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            # Move inputs and labels to the target device (GPU/CPU)\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # Subtract 1 from the target values to shift them to the range 0-25\n",
    "            labels = (labels - 1).to(device)\n",
    "            # Forward Pass\n",
    "            outputs = model(inputs)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "\n",
    "            # Get top-5 predictions for each sample\n",
    "            _, top5_predictions = outputs.topk(5, dim=1)\n",
    "\n",
    "            # Ensure both top5_predictions and labels are on the same device\n",
    "            top5_predictions = top5_predictions.to(device)  # Move top5 predictions to the same device as labels\n",
    "\n",
    "            # Check for Top-1 accuracy\n",
    "            top1_predictions = outputs.argmax(dim=1)\n",
    "            correct_predictions_top1 += (top1_predictions == labels).sum().item()\n",
    "\n",
    "            # Check for Top-5 accuracy (true label should be in the top 5 predictions)\n",
    "            correct_predictions_top5 += (top5_predictions == labels.view(-1, 1)).any(dim=1).sum().item()\n",
    "\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    # Calculate Average Validation loss and Accuracy for the epoch\n",
    "    avg_loss = loss / len(data_loader)\n",
    "    top1_accuracy = 100 * correct_predictions_top1 / total_samples\n",
    "    top5_accuracy = 100 * correct_predictions_top5 / total_samples\n",
    "\n",
    "    return avg_loss, top1_accuracy, top5_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39fa1bd-9135-45c5-af31-e0be61cf8a0c",
   "metadata": {},
   "source": [
    "# Inferencing on Validation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e900dbc-80b1-461f-bcf4-dc5f58ed6e48",
   "metadata": {},
   "source": [
    "## CoupledNet Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782373c-da1e-48fa-9622-aefd6d42ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "Best_model.eval()\n",
    "\n",
    "avg_loss, top1_accuracy, top5_accuracy = top_accuracy(Best_model, val_loader, criterion, device)\n",
    "\n",
    "# Print the final Validation loss and accuracy\n",
    "print('\\n')\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"######################## CoupledNet ########################\")\n",
    "print(\"------------- Inference on Validation Dataset --------------\")\n",
    "print(f\"Top-1 Accuracy: {top1_accuracy:.4f}%, Top-5 Accuracy: {top5_accuracy:.4f}%, Validation Loss: {avg_loss:.6f}.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65859509-f1aa-4a41-abe7-4bec66a36a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the file\n",
    "log_file.close()\n",
    "\n",
    "# Reset stdout to default\n",
    "sys.stdout = sys.__stdout__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
