{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a23a0140-069f-4ad4-befc-c2555bc14391",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c46054-b2a7-42c3-b95a-3ec7068f9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os, sys, time, gc, random\n",
    "\n",
    "# PyTorch Core Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "# Additional Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# System Monitoring (GPU/CPU)\n",
    "import psutil\n",
    "from pynvml import *\n",
    "\n",
    "# Initialize NVML for GPU monitoring\n",
    "nvmlInit()\n",
    "gc.collect()  # Explicitly call garbage collection to clean up memory\n",
    "torch.cuda.empty_cache()  # Clear unused memory\n",
    "\n",
    "\"\"\" Reproducibility \"\"\"\n",
    "# Define seed value\n",
    "seed = 42\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(seed)  # Python's random module\n",
    "np.random.seed(seed)  # NumPy random module\n",
    "torch.manual_seed(seed)  # PyTorch CPU random seed\n",
    "# Check if CUDA is available and set the seed for CUDA as well\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)  # PyTorch GPU random seed (for current device)\n",
    "    torch.cuda.manual_seed_all(seed) # PyTorch GPU random seed (for all devices, if multi-GPU)\n",
    "\n",
    "# For deterministic behavior with cuDNN (when using GPU)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False  # Disables the cudnn autotuner to ensure reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db12cab8-36c3-479b-aba6-f7d1cc18a156",
   "metadata": {},
   "source": [
    "#### Redirecting Print Output to a Log File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f68d6-132b-49a1-b014-ac814bc8f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main parameters\n",
    "MODEL_NAME = \"(d)784-256-128-64-32-10\" # Target Model\n",
    "DATASET_NAME = \"EMNIST\" # Target Dataset\n",
    "NUM_CLASSES = 26 # No of classes\n",
    "split_ratio = 0.85 # Split training set into training and validation\n",
    "ALPHAS = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a29ef23-142e-466d-94e0-ef92840bce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ALPHA in ALPHAS:\n",
    "    FOLDER_NAME = f\"{DATASET_NAME}/{MODEL_NAME}\"\n",
    "    if not os.path.exists(FOLDER_NAME):\n",
    "        os.makedirs(FOLDER_NAME)\n",
    "    \n",
    "    log_file_path = os.path.join(FOLDER_NAME, f\"a{ALPHA}-logfile.txt\")\n",
    "    log_file = open(log_file_path, 'w')\n",
    "    sys.stdout = log_file\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f'{device} is available...')\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "    if num_gpus > 0:\n",
    "        print(f\"GPU Name: {torch.cuda.get_device_name(0)}\\n\")\n",
    "    \n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.init()\n",
    "        torch.cuda.current_device()\n",
    "        torch.zeros(1).to(device)\n",
    "    \n",
    "    batch_size = 128\n",
    "    num_workers = 16\n",
    "    learning_rate = 1e-3\n",
    "    num_epochs = 300\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    patience = 15\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_without_improvement = 0\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.17222732305526733], std=[0.3309466242790222])\n",
    "    ])\n",
    "    \n",
    "    val_test_transform  = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.17222732305526733], std=[0.3309466242790222])\n",
    "    ])\n",
    "    \n",
    "    class TransformedDataset(Dataset):\n",
    "        def __init__(self, dataset, transform):\n",
    "            self.dataset = dataset\n",
    "            self.transform = transform\n",
    "        def __getitem__(self, index):\n",
    "            img, label = self.dataset[index]\n",
    "            return self.transform(img), label\n",
    "    \n",
    "        def __len__(self):\n",
    "            return len(self.dataset)\n",
    "            \n",
    "    train_set = datasets.EMNIST(root=f\"./{DATASET_NAME}/data\", split='letters', train=True, download=True, transform=None)\n",
    "    test_set = datasets.EMNIST(root=f\"./{DATASET_NAME}/data\", split='letters', train=False, download=True, transform=val_test_transform)\n",
    "    train_size = int(split_ratio * len(train_set))\n",
    "    val_size = len(train_set) - train_size\n",
    "    raw_train, raw_val = random_split(train_set, [train_size, val_size])\n",
    "    \n",
    "    train_dataset = TransformedDataset(raw_train, train_transform)\n",
    "    val_dataset = TransformedDataset(raw_val, val_test_transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=num_workers,\n",
    "                              pin_memory=True, \n",
    "                              persistent_workers=True\n",
    "                             )\n",
    "    \n",
    "    val_loader = DataLoader(val_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=num_workers,\n",
    "                              pin_memory=True, \n",
    "                              persistent_workers=True\n",
    "                             )\n",
    "    \n",
    "    test_loader = DataLoader(test_set,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=num_workers,\n",
    "                              pin_memory=True, \n",
    "                              persistent_workers=True\n",
    "                             )\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(f\"Number of imgaes in train_loader: {len(train_loader.dataset)}\")\n",
    "    print(f\"Number of imgaes in val_loader: {len(val_loader.dataset)}\")\n",
    "    print(f\"Number of imgaes in test_loader: {len(test_loader.dataset)}\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    class FCNN(nn.Module):\n",
    "        def __init__(self, input_dim=784, output_dim=10):\n",
    "            super(FCNN, self).__init__()\n",
    "            self.flatten = nn.Flatten()\n",
    "            self.fc1 = nn.Linear(input_dim, 256)\n",
    "            self.fc2 = nn.Linear(256, 128)\n",
    "            self.fc3 = nn.Linear(128, 64)\n",
    "            self.fc4 = nn.Linear(64, 32)\n",
    "            self.fc5 = nn.Linear(32, output_dim)\n",
    "            self.relu = nn.ReLU()\n",
    "    \n",
    "        def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "            x = self.flatten(x)\n",
    "            x = self.relu(self.fc1(x))\n",
    "            x = self.relu(self.fc2(x))\n",
    "            x = self.relu(self.fc3(x))\n",
    "            x = self.relu(self.fc4(x))\n",
    "            x = self.fc5(x)\n",
    "            return x\n",
    "    \n",
    "    model = FCNN()\n",
    "    model.to(device)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"           Model & Data Pipeline Summary\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Model Architecture:\\n{model}\")\n",
    "    \n",
    "    print(\"\\n\\nModel Summary:\")\n",
    "    summary(model, (1, 28, 28))\n",
    "    \n",
    "    def train_loop(model, train_loader, optimizer, criterion, device):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "    \n",
    "        num_batches = len(train_loader)\n",
    "        batch_print_interval = max(1, num_batches // 5)\n",
    "    \n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "            labels = (labels - 1).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            predictions = outputs.argmax(dim=1)\n",
    "            correct_predictions += (predictions == labels).sum().item()\n",
    "            total_samples += inputs.size(0)\n",
    "    \n",
    "            if batch_idx % batch_print_interval == 0:\n",
    "                batch_loss = loss.item()\n",
    "                batch_accuracy = (predictions == labels).sum().item() / inputs.size(0) * 100.0\n",
    "                print(f\"Batch {batch_idx+1}/{len(train_loader)} - \"\n",
    "                      f\"Batch Loss: {batch_loss:.6f}, Batch Accuracy: {batch_accuracy:.4f}%\")\n",
    "    \n",
    "        train_loss = running_loss / total_samples\n",
    "        train_accuracy = correct_predictions / total_samples * 100.0\n",
    "    \n",
    "        return train_loss, train_accuracy\n",
    "    \n",
    "    def val_test_loop(model, data_loader, criterion, device, compute_top5=False):\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct_predictions_top1 = 0\n",
    "        correct_predictions_top5 = 0\n",
    "        total_samples = 0\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in data_loader:\n",
    "                inputs = inputs.to(device, non_blocking=True)\n",
    "                labels = labels.to(device, non_blocking=True)\n",
    "                labels = (labels - 1).to(device)\n",
    "    \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "    \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                predictions = outputs.argmax(dim=1)\n",
    "                correct_predictions_top1 += (predictions == labels).sum().item()\n",
    "                total_samples += inputs.size(0)\n",
    "                \n",
    "                if compute_top5:\n",
    "                    _, top5_predictions = outputs.topk(5, dim=1)\n",
    "                    correct_predictions_top5 += (top5_predictions == labels.view(-1, 1)).any(dim=1).sum().item()\n",
    "    \n",
    "        avg_loss = running_loss / total_samples\n",
    "        top1_accuracy = correct_predictions_top1 / total_samples * 100.0\n",
    "        val_test_results = {\n",
    "            'top1_accuracy': top1_accuracy,\n",
    "            'loss': avg_loss,\n",
    "        }\n",
    "        \n",
    "        if compute_top5:\n",
    "            top5_accuracy = correct_predictions_top5 / total_samples * 100.0\n",
    "            val_test_results['top5_accuracy'] = top5_accuracy\n",
    "    \n",
    "        return val_test_results\n",
    "    \n",
    "    def save_epoch_results(epoch, current_lr, running_train_loss, running_train_accuracy, val_loss, val_accuracy, KE_val_loss, KE_val_accuracy,\n",
    "                            epoch_time, KE_time, KE_with_V_time, FOLDER_NAME):\n",
    "        epoch_data = {\n",
    "            'Epoch': [epoch+1],\n",
    "            'LR' : [current_lr],\n",
    "            'Running Train Loss': [running_train_loss], \n",
    "            'Running Train Accuracy': [running_train_accuracy],\n",
    "            'Validation Loss': [val_loss],\n",
    "            'Validation Accuracy': [val_accuracy],\n",
    "            'KE Validation Loss': [KE_val_loss],\n",
    "            'KE Validation Accuracy': [KE_val_accuracy],\n",
    "            'Epoch Time': [epoch_time],\n",
    "            'KE Time': [KE_time],\n",
    "            'KE + Forward Pass Time': [KE_with_V_time],\n",
    "        }\n",
    "    \n",
    "        df = pd.DataFrame(epoch_data)\n",
    "        file_path = os.path.join(FOLDER_NAME, f'a{ALPHA}-epoch_results.csv')\n",
    "        header = not os.path.exists(file_path)\n",
    "        df.to_csv(file_path, mode='a', header=header, index=False)\n",
    "        print(f\"Epoch {epoch+1} results saved...\")\n",
    "    \n",
    "    def save_checkpoint(model, optimizer, epoch, FOLDER_NAME):\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }\n",
    "        checkpoint_path = os.path.join(FOLDER_NAME, f\"a{ALPHA}-checkpoint_epoch_{epoch+1}.pth\")\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"Checkpoint saved at epoch {epoch+1} to {checkpoint_path}...\")\n",
    "    \n",
    "    def summarize_gpu_info():\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        for i in range(num_gpus):\n",
    "            handle = nvmlDeviceGetHandleByIndex(i)\n",
    "            mem_info = nvmlDeviceGetMemoryInfo(handle)\n",
    "            gpu_util = nvmlDeviceGetUtilizationRates(handle)\n",
    "            gpu_temp = nvmlDeviceGetTemperature(handle, NVML_TEMPERATURE_GPU)\n",
    "            print(f\"GPU {i}:\")\n",
    "            print(f\"  Memory Usage: {mem_info.used / 1024 ** 2} MB (Used) / {mem_info.total / 1024 ** 2} MB (Total)\")\n",
    "            print(f\"  GPU Utilization: {gpu_util.gpu} %\")\n",
    "            print(f\"  GPU Temperature: {gpu_temp} °C\")\n",
    "        print(f\"CPU Usage: {psutil.cpu_percent()}%\")\n",
    "        print(f\"Memory Usage: {psutil.virtual_memory().percent}%\")\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    \n",
    "    def Callback(model):\n",
    "        if isinstance(model, nn.DataParallel):\n",
    "            model = model.module\n",
    "        with torch.no_grad():\n",
    "            fc1_weights = model.fc1.weight\n",
    "            fc1_biases = model.fc1.bias\n",
    "            for i in range(1, ALPHA * 2, 2):\n",
    "                fc1_weights[i].copy_(fc1_weights[i - 1])\n",
    "                fc1_biases[i].copy_(fc1_biases[i - 1]) \n",
    "    \n",
    "    from torch.optim import AdamW\n",
    "    from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "    \n",
    "    optimizer = AdamW(\n",
    "        model.parameters(),\n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-4,\n",
    "        betas=(0.9, 0.999)\n",
    "    )\n",
    "    \n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"#\" * 60)\n",
    "    print(f\"#         TRAINING STARTED: {MODEL_NAME} on {DATASET_NAME} Dataset        #\")\n",
    "    print(\"#\" * 60 + \"\\n\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "    \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"........... Epoch {epoch+1} Start - GPU & CPU monitoring ...........\")\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        summarize_gpu_info()\n",
    "    \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"...................... Epoch {epoch+1} Start .......................\")\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "        running_train_loss, running_train_accuracy = train_loop(model, train_loader, optimizer, criterion, device)\n",
    "        val_metrics = val_test_loop(model, val_loader, criterion, device)\n",
    "        val_loss = val_metrics['loss']\n",
    "        val_accuracy = val_metrics['top1_accuracy']\n",
    "        epoch_time = time.time() - epoch_start \n",
    "        \n",
    "        KE_start = time.time()\n",
    "        Callback(model)\n",
    "        KE_time = time.time() - KE_start\n",
    "        \n",
    "        KE_val_metrics = val_test_loop(model, val_loader, criterion, device)\n",
    "        KE_val_loss = KE_val_metrics['loss']\n",
    "        KE_val_accuracy = KE_val_metrics['top1_accuracy']\n",
    "        KE_with_V_time = time.time() - KE_start\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"...................... Epoch {epoch+1} Results .....................\")\n",
    "        print('--------------- Before Callback -----------------')\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} Summary:\")\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"Running Train Loss: {running_train_loss:.6f}, Running Train Accuracy: {running_train_accuracy:.4f}%\")\n",
    "        print(f\"Validation Loss: {val_loss:.6f}, Validation Accuracy: {val_accuracy:.4f}%\")\n",
    "    \n",
    "        print('\\n---------------- After Callback -----------------')\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} Summary:\")\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"Validation Loss: {KE_val_loss:.6f}, Validation Accuracy: {KE_val_accuracy:.4f}%\")\n",
    "        \n",
    "        print(f\"\\n~~~*~~~ Time Consumptions ~~~*~~~\")\n",
    "        print(f\"Epoch {epoch+1} completed in {epoch_time/60:.4f} minutes.\")\n",
    "        print(f\"Time Consumption of Callback: {KE_time:.6f} seconds.\")\n",
    "        print(f\"Time Consumption of Callback + Forward Pass Validation dataset: {KE_with_V_time/60:.4f} minutes.\")\n",
    "        print(f\"Time Elapsed Since Epoch {epoch + 1} Started: {(time.time() - epoch_start)/60:.4f} minutes.\")\n",
    "        print(f\"Total Time Elapsed Since Training Started: {(time.time() - start_time)/60:.4f} minutes.\\n\")  \n",
    "            \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "        save_epoch_results(epoch, current_lr, running_train_loss, running_train_accuracy, val_loss, val_accuracy, KE_val_loss, KE_val_accuracy,\n",
    "                            epoch_time, KE_time, KE_with_V_time, FOLDER_NAME)\n",
    "    \n",
    "        print(f\"\\n.........Epoch {epoch+1} End - GPU & CPU monitoring.........\")\n",
    "        summarize_gpu_info()\n",
    "    \n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            save_checkpoint(model, optimizer, epoch, FOLDER_NAME)\n",
    "    \n",
    "        print(\"=\"*60)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "            model_weights_path = os.path.join(FOLDER_NAME, f\"a{ALPHA}-best_model.pth\")\n",
    "            torch.save(model.state_dict(), model_weights_path)\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            \n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(\"\\n================ Early Stopping Triggered! =================\\n\")\n",
    "            break\n",
    "    \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    print(f\"\\nTraining complete! Total time : {total_time:.4f} seconds.\")\n",
    "    print(f\"                              : {total_time / 60:.4f} minutes.\")\n",
    "    print(f\"                              : {total_time / 3600:.4f} hours.\")\n",
    "    print(f\"                              : {total_time / 86400:.4f} days.\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\n*~*~*~*~*~*~*~*~*~*~*~*~*~* THE END *~*~*~*~*~*~*~*~*~*~*~*~*~*\\n\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    nvmlShutdown()\n",
    "    \n",
    "    Best_model = FCNN()\n",
    "    weights_path = os.path.join(FOLDER_NAME, f\"a{ALPHA}-best_model.pth\")\n",
    "    state_dict = torch.load(weights_path, map_location=device, weights_only=True)\n",
    "    \n",
    "    if any(k.startswith(\"module.\") for k in state_dict):\n",
    "        new_state_dict = {}\n",
    "        for k, v in state_dict.items():\n",
    "            new_key = k.replace(\"module.\", \"\")\n",
    "            new_state_dict[new_key] = v\n",
    "        state_dict = new_state_dict\n",
    "    Best_model.load_state_dict(state_dict)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        Best_model = nn.DataParallel(Best_model)\n",
    "    Best_model = Best_model.to(device)\n",
    "    Callback(Best_model)\n",
    "    Best_model.eval()\n",
    "    test_metrics  = val_test_loop(Best_model, test_loader, criterion, device, compute_top5=True)\n",
    "    \n",
    "    print('\\n')\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"######################## CoupledNet ########################\")\n",
    "    print(\"------------- Inference on Validation Dataset --------------\")\n",
    "    print(f\"Top-1 Accuracy: {test_metrics['top1_accuracy']:.4f}%, Top-5 Accuracy: {test_metrics['top5_accuracy']:.4f}%, Test Loss: {test_metrics['loss']:.6f}.\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    import copy\n",
    "    \n",
    "    RE_model = copy.deepcopy(Best_model)\n",
    "    Random_model = FCNN().to(device)\n",
    "    RE_model.eval()\n",
    "    Random_model.eval()\n",
    "    \n",
    "    Best_model = Best_model.module if isinstance(Best_model, nn.DataParallel) else Best_model\n",
    "    RE_model = RE_model.module if isinstance(RE_model, nn.DataParallel) else RE_model\n",
    "    Random_model = Random_model.module if isinstance(Random_model, nn.DataParallel) else Random_model\n",
    "    \n",
    "    def RE_calc(layer_name: str, affected_layer_name: str, ALPHA: int, Best_model: nn.Module, RE_model: nn.Module, Random_model: nn.Module):\n",
    "        Best_layer = getattr(Best_model, layer_name)\n",
    "        RE_layer = getattr(RE_model, layer_name)\n",
    "        Random_layer = getattr(Random_model, layer_name)\n",
    "        \n",
    "        W = Best_layer.weight.data.clone()\n",
    "        B = Best_layer.bias.data.clone()\n",
    "        \n",
    "        device = W.device\n",
    "        \n",
    "        neg_bias = B < 0\n",
    "        negative_bias_mask = neg_bias[:, None].expand_as(W)\n",
    "        \n",
    "        negative_weight_mask = W < 0\n",
    "        CASE4_mask = negative_bias_mask & negative_weight_mask        \n",
    "        Final_mask = CASE4_mask.clone()\n",
    "        \n",
    "        if layer_name == affected_layer_name:\n",
    "            Final_mask[:, :2*ALPHA] = True\n",
    "            has_only_neg = torch.all(CASE4_mask[:, 2*ALPHA:], dim=1)\n",
    "            Final_mask[has_only_neg, 2*ALPHA:] = True\n",
    "            Final_mask[~has_only_neg, 2*ALPHA:] = False\n",
    "            RE_layer.weight.data[Final_mask] = Random_layer.weight.data[Final_mask]\n",
    "        \n",
    "        dummy_mask = torch.all(CASE4_mask, dim=1)\n",
    "        Final_mask[dummy_mask, :] = True\n",
    "        Final_mask[~dummy_mask, :] = False\n",
    "        RE_layer.weight.data[Final_mask] = Random_layer.weight.data[Final_mask]\n",
    "    \n",
    "    print('\\n')\n",
    "    print(\"################## Reverse Engineering #####################\")\n",
    "    with torch.no_grad():\n",
    "        for name, layer in Best_model.named_children():\n",
    "            if isinstance(layer, nn.Linear) and name != \"fc1\":\n",
    "                print(f\"Processing layer: {name}\")\n",
    "                RE_calc(layer_name=name, affected_layer_name=\"fc2\", ALPHA=ALPHA, Best_model=Best_model, RE_model=RE_model, Random_model=Random_model)\n",
    "                print(f\"Done..\")\n",
    "    print(f\"Number of Epochs: {epoch - patience}\")\n",
    "    \n",
    "    RE_model_parallel = nn.DataParallel(RE_model).to(device)\n",
    "    Random_model_parallel = nn.DataParallel(Random_model).to(device)\n",
    "    \n",
    "    RE_test_metrics  = val_test_loop(RE_model, test_loader, criterion, device, compute_top5=True)\n",
    "    Random_test_metrics  = val_test_loop(Random_model, test_loader, criterion, device, compute_top5=True)\n",
    "    \n",
    "    print(\"\\n------------- Inference on Validation Dataset --------------\")\n",
    "    print(f\"Top-1 Accuracy: {RE_test_metrics['top1_accuracy']:.4f}%, Top-5 Accuracy: {RE_test_metrics['top5_accuracy']:.4f}%, Test Loss: {RE_test_metrics['loss']:.6f}.\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\n------------- Random Model - testing purpose --------------\")\n",
    "    print(f\"Top-1 Accuracy: {Random_test_metrics['top1_accuracy']:.4f}%, Top-5 Accuracy: {Random_test_metrics['top5_accuracy']:.4f}%, Test Loss: {Random_test_metrics['loss']:.6f}.\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    log_file.close()\n",
    "    sys.stdout = sys.__stdout__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
